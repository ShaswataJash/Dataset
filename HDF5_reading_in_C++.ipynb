{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNCZeAVQnsYdmkgZYf9AoK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaswataJash/LargeDatasetHandling/blob/master/HDF5_reading_in_C%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installation of required software packages"
      ],
      "metadata": {
        "id": "4Pu-jAqrasbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py==3.8.0"
      ],
      "metadata": {
        "id": "U5wZBh7dyDZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ref: https://docs.h5py.org/en/stable/mpi.html\n",
        "#check whether parallel version of h5py is availiable\n",
        "!h5cc -showconfig"
      ],
      "metadata": {
        "id": "TN3pxs5zhvGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install hdf5plugin~=2.0\n",
        "#Installation from source can achieve better performances than pre-built binaries. (refer: http://www.silx.org/doc/hdf5plugin/latest/install.html)\n",
        "!pip install -vv hdf5plugin --no-binary hdf5plugin\n",
        "#!pip install hdf5plugin==4.1.1"
      ],
      "metadata": {
        "id": "GsjShaVYyIg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ref: https://www.silx.org/doc/hdf5plugin/latest/hdf5plugin_EuropeanHUG2022.html\n",
        "%%bash\n",
        "export HDF5_PLUGIN_PATH=`python3 -c \"\n",
        "import hdf5plugin; print(hdf5plugin.PLUGINS_PATH)\"`\n",
        "echo \"HDF5_PLUGIN_PATH=${HDF5_PLUGIN_PATH}\"\n",
        "ls ${HDF5_PLUGIN_PATH}"
      ],
      "metadata": {
        "id": "PbvezqRtIEf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /usr/lib/x86_64-linux-gnu/hdf5/serial"
      ],
      "metadata": {
        "id": "aDloTqjXOg1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#needed if c++ is being used for hdf5 access\n",
        "!mkdir /usr/lib/x86_64-linux-gnu/hdf5/plugins\n",
        "!cp /usr/local/lib/python3.10/dist-packages/hdf5plugin/plugins/* /usr/lib/x86_64-linux-gnu/hdf5/plugins"
      ],
      "metadata": {
        "id": "LMcREaKMJ-ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.12/hdf5-1.12.1/bin/unix/hdf5-1.12.1-Std-ubuntu2010_64.tar.gz"
      ],
      "metadata": {
        "id": "BklpjFdzdgZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf hdf5-1.12.1-Std-ubuntu2010_64.tar.gz"
      ],
      "metadata": {
        "id": "ny-6tlRC_uZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hdf/HDF5-1.12.1-Linux.sh"
      ],
      "metadata": {
        "id": "wiUCo3M7ADd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer https://support.hdfgroup.org/HDF5/doc/TechNotes/TechNote-HDF5-ImprovingIOPerformanceCompressedDatasets.pdf to understand the utility of the binary h5ls and then h5dump. In h5dump, **specifically note the compression ratio**."
      ],
      "metadata": {
        "id": "GjedGyFXFX7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!HDF5-1.12.1-Linux/HDF_Group/HDF5/1.12.1/bin/h5ls -lrv /mnt/train_multi_inputs.h5"
      ],
      "metadata": {
        "id": "YeW9eVLEBVxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!HDF5-1.12.1-Linux/HDF_Group/HDF5/1.12.1/bin/h5dump -H -p -d /train_multi_inputs/block0_values /mnt/train_multi_inputs.h5"
      ],
      "metadata": {
        "id": "uyYmDIKAD62U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HDF5 reading through C++"
      ],
      "metadata": {
        "id": "o18DygWPknmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -Rf HighFive\n",
        "!git clone https://github.com/BlueBrain/HighFive.git"
      ],
      "metadata": {
        "id": "LwkePc9rkuFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm tqdm.cpp\n",
        "!git clone https://github.com/tqdm/tqdm.cpp.git"
      ],
      "metadata": {
        "id": "yUW1pyjer4qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ref: https://pytorch.org/get-started/locally/ [Choose > Stable: Linux: LibTorch: C++: cpu]\n",
        "!wget https://download.pytorch.org/libtorch/cpu/libtorch-cxx11-abi-shared-with-deps-2.0.0%2Bcpu.zip\n",
        "!unzip libtorch-cxx11*.zip"
      ],
      "metadata": {
        "id": "KBZ5fQQvus1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir torch_example_app"
      ],
      "metadata": {
        "id": "1CTZCKCBt_Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile torch_example_app/CMakeLists.txt\n",
        "\n",
        "cmake_minimum_required(VERSION 3.0 FATAL_ERROR)\n",
        "project(example-app)\n",
        "\n",
        "find_package(Torch REQUIRED)\n",
        "list(APPEND CMAKE_PREFIX_PATH \"<my-libtorch-path>\")\n",
        "set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}\")\n",
        "include_directories(\n",
        "  \"${TORCH_INCLUDE_DIRS}\"\n",
        ")\n",
        "add_executable(example-app example-app.cpp)\n",
        "target_link_libraries(example-app \"${TORCH_LIBRARIES}\")\n",
        "set_property(TARGET example-app PROPERTY CXX_STANDARD 14)"
      ],
      "metadata": {
        "id": "-DFQOY33xpO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile torch_example_app/example-app.cpp\n",
        "\n",
        "#include <torch/torch.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main() {\n",
        "  const torch::Tensor& tensor1 = torch::rand({5, 3});\n",
        "  std::cout << \"tensor1:\\n\" << tensor1 << &tensor1 << std::endl;\n",
        "\n",
        "  const std::tuple<at::Tensor, at::Tensor>& min_res = at::min(tensor1, 0, true);\n",
        "  std::cout << \"min_res of tensor1:\\n\" << std::get<0>(min_res) << \"index of min_res=\" << std::get<1>(min_res)  << std::endl;\n",
        "\n",
        "  const torch::Tensor& tensor2 = torch::rand({1, 3});\n",
        "  std::cout << \"tensor2:\\n\" << tensor2 << &tensor2 << std::endl;\n",
        "\n",
        "  const torch::Tensor& min = at::min(std::get<0>(min_res), tensor2);\n",
        "  std::cout << \"min between min_res of tensor1 and tensor2:\\n\" << min << &min << std::endl;\n",
        "\n",
        "  torch::Tensor r = torch::rand({1, 3});\n",
        "  std::cout << \"random tensor r:\\n\" << r << &r << std::endl;\n",
        "  const torch::Tensor& after_copy = at::copy_out(r, r, min);\n",
        "  std::cout << \"tensor r (after copy from min):\\n\" << r << &r << std::endl;\n",
        "  std::cout << \"result_r after_copy (after copy from min):\\n\" << after_copy << &after_copy << std::endl;\n",
        "  \n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "xDaxE0eBuQ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir torch_example_app/build\n",
        "%cd torch_example_app/build\n",
        "!cmake -DCMAKE_PREFIX_PATH=/content/libtorch ..\n",
        "!cmake --build . --config Release\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "7XavALSSujiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./torch_example_app/build/example-app"
      ],
      "metadata": {
        "id": "aAcN6YVyvdhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir torch_example_along_with_hdf5"
      ],
      "metadata": {
        "id": "mEXonOY2wovt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile torch_example_along_with_hdf5/hdf5reading.cpp\n",
        "\n",
        "#include <torch/torch.h>\n",
        "\n",
        "#include <highfive/H5File.hpp>\n",
        "#include <highfive/H5DataSet.hpp>\n",
        "#include <highfive/H5DataSpace.hpp>\n",
        "using namespace HighFive;\n",
        "\n",
        "#include \"tqdm/tqdm.h\"\n",
        "\n",
        "#include <algorithm>\n",
        "#include <iostream>\n",
        "\n",
        "const std::string FILE_NAME(\"/mnt/train_multi_inputs.h5\");\n",
        "const int BATCH_SIZE = 4000;\n",
        "int main(void) {\n",
        "\n",
        "    try {\n",
        "        // We open the file as read-only:\n",
        "        File file(FILE_NAME, File::ReadOnly);\n",
        "        const DataSet& dataset = file.getDataSet(\"/train_multi_inputs/block0_values\");\n",
        "\n",
        "        // get the dimension of the dataset\n",
        "        const std::vector< size_t >& dim = dataset.getDimensions();\n",
        "        std::cout << \"dimension:(\" << dim[0] << \",\" <<  dim[1] << \")\" << std::endl; \n",
        "\n",
        "        const DataType& dType = dataset.getDataType();\n",
        "        std::cout << \"datatype:\" << dType.string() << std::endl; \n",
        "\n",
        "        //float *result = new float[BATCH_SIZE * dim[1]];\n",
        "        auto options = torch::TensorOptions().dtype(torch::kFloat32).requires_grad(false);\n",
        "        torch::Tensor pre_allocated_tensor = torch::zeros({BATCH_SIZE, dim[1]}, options);\n",
        "        //ref: https://discuss.pytorch.org/t/can-i-get-the-cuda-tensor-pointer-in-the-python-pytorch/141195\n",
        "        float *result = pre_allocated_tensor.data_ptr<float>();\n",
        "\n",
        "        torch::Tensor max_t = torch::zeros({1, dim[1]}, options);\n",
        "        torch::Tensor min_t = torch::zeros({1, dim[1]}, options); \n",
        "        bool not_inited = false;\n",
        "        for (int startingRow : tqdm::range(0, (int)dim[0], BATCH_SIZE)){\n",
        "            \n",
        "            dataset.select({startingRow, 0}, {std::min(BATCH_SIZE, (int)(dim[0]) - startingRow), dim[1]}).read(result);\n",
        "            \n",
        "            const std::tuple<at::Tensor, at::Tensor>& max_col = at::max(pre_allocated_tensor, 0, true); //max finding along dimension 0\n",
        "            const std::tuple<at::Tensor, at::Tensor>& min_col = at::min(pre_allocated_tensor, 0, true); //min finding along dimension 0\n",
        "\n",
        "            //std::cout << \"startingRow : \" << startingRow << std::endl;\n",
        "            if (not_inited){\n",
        "                at::copy_out(max_t, max_t, std::get<0>(max_col));\n",
        "                at::copy_out(min_t, min_t, std::get<0>(min_col));\n",
        "            }else{\n",
        "                const torch::Tensor& local_max = at::max(std::get<0>(max_col), max_t);\n",
        "                const torch::Tensor& local_min = at::max(std::get<0>(min_col), min_t);\n",
        "                at::copy_out(max_t, max_t, local_max);\n",
        "                at::copy_out(min_t, min_t, local_min);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        //delete [] result;\n",
        "\n",
        "    } catch (Exception& err) {\n",
        "        // catch and print any HDF5 error\n",
        "        std::cerr << err.what() << std::endl;\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    return 0;  // successfully terminated\n",
        "}"
      ],
      "metadata": {
        "id": "5sWwb0SKlJ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/BlueBrain/HighFive/issues/350 (why  /usr/include/hdf5/serial has to be included?)\n",
        "%%writefile torch_example_along_with_hdf5/CMakeLists.txt\n",
        "\n",
        "cmake_minimum_required(VERSION 3.0 FATAL_ERROR)\n",
        "project(torch-hdf5-example-app)\n",
        "\n",
        "find_package(Torch REQUIRED)\n",
        "list(APPEND CMAKE_PREFIX_PATH \"<my-libtorch-path>\")\n",
        "set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}\")\n",
        "include_directories(\n",
        "  \"${TORCH_INCLUDE_DIRS}\" \"/content/HighFive/include/\" \"/usr/include/hdf5/serial\" \"/content/tqdm.cpp/include\"\n",
        ")\n",
        "link_directories(\"/usr/lib/x86_64-linux-gnu/hdf5/serial/\")\n",
        "add_executable(torch-hdf5-example-app hdf5reading.cpp)\n",
        "target_link_libraries(torch-hdf5-example-app \"${TORCH_LIBRARIES}\" \"hdf5\")\n",
        "set_property(TARGET torch-hdf5-example-app PROPERTY CXX_STANDARD 14)"
      ],
      "metadata": {
        "id": "kyapWHvm8W3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "1l4Jb_CL1v1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir torch_example_along_with_hdf5/build\n",
        "%cd torch_example_along_with_hdf5/build\n",
        "!cmake -DCMAKE_PREFIX_PATH=/content/libtorch ..\n",
        "!cmake --build . --config Release\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "ft5ZjqzGRZvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "2C6qxIjR5Qn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./torch_example_along_with_hdf5/build/torch-hdf5-example-app"
      ],
      "metadata": {
        "id": "4mIErAjj-kt-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}